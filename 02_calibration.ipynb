{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration of Imbalance weights $w$, LOB Price Deviation $dp^+$ as well as Market Order Price Impact $dq$\n",
    "\n",
    "## Preparation of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skewnorm\n",
    "from datetime import datetime\n",
    "from bisect import bisect_left\n",
    "import mystic\n",
    "from mystic.symbolic import generate_constraint, generate_solvers, generate_penalty, generate_conditions, simplify\n",
    "from mystic.monitors import VerboseMonitor\n",
    "from mystic.solvers import diffev2, fmin_powell\n",
    "from random import choices\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.offline import iplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the data\n",
    "#Unzip the datafile before loading\n",
    "lob = pd.read_csv('./data/20170417_AEM_limit_order_book.csv')\n",
    "lob.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For resampling reasons, we convert the time in seconds.nanosc to prepare for calibration\n",
    "lob['time'] = pd.to_datetime(lob['time']).apply(lambda x: (x - datetime(1970,1,1)).total_seconds())\n",
    "lob['time'] = lob['time'] + 1e-9  * lob['time_nanos']\n",
    "lob.sort_values('time', inplace=True)\n",
    "\n",
    "#Transform unit of price into ticks\n",
    "name_ask = ['pa' + str(i) for i in range(10)]\n",
    "name_bid = ['pb' + str(i) for i in range(10)]\n",
    "lob[name_ask] = 100 * lob[name_ask]\n",
    "lob[name_bid] = 100 * lob[name_bid]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal depth and sample frequenty\n",
    "\n",
    "We sample the data every $f$ seconds and compute best ask price change as $dp_a(t) = p_a(t) - p_a(t-f)$.\n",
    "The sampling frequency is \n",
    "\\begin{equation*}\n",
    "    \\mathop{\\arg\\min}\\limits_{f > 0} |\\sigma^2 - \\sigma_f^2 |     \n",
    "\\end{equation*}\n",
    "when $\\sigma_f^2$ , the variance of $dp_a$ is the closest to a given benchmark variance $\\sigma^2 = 2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def takeClosest(myList, myNumber):\n",
    "    #Assumes myList is sorted. Returns closest value to myNumber.\n",
    "    pos = bisect_left(myList, myNumber)\n",
    "    if pos == 0:\n",
    "        return pos\n",
    "    if pos == len(myList):\n",
    "        return -1\n",
    "    before = myList[pos - 1]\n",
    "    after = myList[pos]\n",
    "    #If two numbers are equally close, return the smallest number.  \n",
    "    if after - myNumber < myNumber - before:\n",
    "        return pos\n",
    "    else:\n",
    "        return pos-1\n",
    "    \n",
    "def get_frequency(nums, day, lob):\n",
    "    #Slice the trading day into nums seconds intervals\n",
    "    s = np.array(list(map(lambda x: (x - datetime(1970,1,1)).total_seconds(), pd.date_range(start= day + ' 13:30:00', end=day + ' 20:00:00', freq= str(nums) + 'S'))))\n",
    "    s1 = np.array(s) - nums\n",
    "    \n",
    "    #Since some intervals might not include orders, approximate them by taking the closest trading time in the data\n",
    "    time_ls = list(lob['time'].values)\n",
    "    pointer1 = [takeClosest(time_ls, i) for i in s1]\n",
    "    pointer2 = [takeClosest(time_ls, i) for i in s]\n",
    "    \n",
    "    #Compute the price change dpa \n",
    "    d = lob['pa0'].values[pointer2] - lob['pa0'].values[pointer1] \n",
    "    d = d[np.where(d != None)]\n",
    "    return np.abs(2 - np.var(d)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Give the date\n",
    "day = '2017-04-17'\n",
    "#Find the optimal sampling frequency between 1 second to 360 seconds\n",
    "x = np.array(range(1,360))\n",
    "y = np.array([get_frequency(i,day, lob) for i in x])\n",
    "nums = x[y == y.min()][0]\n",
    "print(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the Figure\n",
    "fig = go.Figure()\n",
    "fig.add_scatter(x = x, y = y)\n",
    "fig.update_yaxes(title = r'$|\\sigma^2 - \\sigma_f^2 | $')\n",
    "fig.update_xaxes(title = r'$f$')\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample the data every $f$ seconds and since some intervals might not include orders, approximate them by taking the closest trading time in the data.\n",
    "\n",
    "Compute depth $N$ as the 99\\% quantile of empirical sampled price change distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.array(list(map(lambda x: (x - datetime(1970,1,1)).total_seconds(), pd.date_range(start= day + ' 13:30:00', end=day + ' 20:00:00', freq= str(nums) + 'S'))))\n",
    "s1 = np.array(s) - nums\n",
    "time_ls = list(lob['time'].values)\n",
    "pointer1 = [takeClosest(time_ls, i) for i in s1]\n",
    "pointer2 = [takeClosest(time_ls, i) for i in s]\n",
    "dp_a = lob['pa0'].values[pointer2] - lob['pa0'].values[pointer1]\n",
    "N = int(np.quantile(dp_a, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the histogram of empirial dp\n",
    "fig = go.Figure()\n",
    "fig.add_histogram(x = dp_a, histnorm = 'probability')\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the weights $w$ as well as $dp^+$ from imbalance, and maximum likelihood.\n",
    "\n",
    "Compute the average imbalance\n",
    "\\begin{equation*}\n",
    "    \\hat{\\imath}(w, t) \n",
    "    = \\frac{\n",
    "        \\sum\\limits_{k\\leq N} w_k \\bar{v}^b_k (t) \n",
    "        }\n",
    "        {\\sum\\limits_{k\\leq N}  w_k \\left(\\bar{v}^b_k (t) + \\bar{v}^a_k (t) \\right)\n",
    "        }\n",
    "\\end{equation*}\n",
    "which sums up order book volumes within a certain time interval weighted by time difference\n",
    "\\begin{align*}\n",
    "    &\\bar{v}^a_k(t) = \\sum\\limits_{t - f \\leq s<t} v_k^a(s) \\Delta s\\\\\n",
    "    &\\bar{v}^b_k(t) = \\sum\\limits_{t - f \\leq s<t} v_k^b(s) \\Delta s\n",
    "\\end{align*}\n",
    "and $\\Delta s_i = s_{i+1} - s_{i}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions to compute the imbalance\n",
    "def sum_limit_order_book(x, pointer1, pointer2, lmo_volume):\n",
    "    left = pointer1[x]\n",
    "    right = pointer2[x]\n",
    "    if left >= right:\n",
    "        return np.zeros(N)\n",
    "    lmo_sum = np.sum(lmo_volume[left:right,:] , axis = 0)  \n",
    "    return lmo_sum.tolist()\n",
    "\n",
    "def imbalance_generate(x, weight, N, ask_sum, bid_sum):\n",
    "    weight = np.array(weight)\n",
    "    if np.sum(ask_sum[x]) == None:\n",
    "        return\n",
    "    B = np.sum(weight * ask_sum[x] + weight * bid_sum[x])\n",
    "    A =  np.sum(weight * (bid_sum[x]))\n",
    "    if B == 0:\n",
    "        return\n",
    "    return A / B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute time delta between two orders\n",
    "delta_s = np.diff(time_ls).tolist()\n",
    "delta_s.insert(0 ,0)\n",
    "lob['time_diff'] = delta_s \n",
    "\n",
    "#Weigh the book volume by time delta\n",
    "for i in range(1, N+1):\n",
    "    name_a = 'va' + str(i) \n",
    "    name_b = 'vb' + str(i) \n",
    "    name_aa = 'va-' + str(i) \n",
    "    name_bb = 'vb-' + str(i)\n",
    "    lob[name_aa] = lob[name_a] * lob['time_diff']\n",
    "    lob[name_bb] = lob[name_b] * lob['time_diff']\n",
    "\n",
    "#Sum up the weighted limit order book within f seconds interval\n",
    "name_ask = ['va-' + str(i) for i in range(1, N+1)]\n",
    "name_bid = ['vb-' + str(i) for i in range(1, N+1)]\n",
    "volume_ask = np.array(lob[name_ask])\n",
    "volume_bid = np.array(lob[name_bid])\n",
    "ask_sum = list(map(lambda x: sum_limit_order_book(x, pointer1, pointer2, volume_ask), range(len(pointer1))))\n",
    "bid_sum = list(map(lambda x: sum_limit_order_book(x, pointer1, pointer2, volume_bid), range(len(pointer1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximize the log likelihood function\n",
    "\\begin{equation}\n",
    "   \\max_{dp^+,w} \\frac{1}{M} \\sum^M_{m=1} \\log p\\left(x_m,  \\hat{\\imath}_m \\right)\n",
    "\\end{equation}\n",
    "where $x_m$ is the empirical price change, $\\hat{\\imath}_m$ the average imbalance for a given weight $w$, \n",
    "\\begin{equation*}\n",
    "    p\\left(x_m,  \\hat{\\imath}_m \\right) = dp_{x_m}\\left(\\hat{\\imath}_m \\right) p(\\hat{\\imath}_m)\n",
    "\\end{equation*}\n",
    "where \n",
    "\\begin{equation*}\n",
    "    dp_{x_m} \\left(\\hat{\\imath}_m\\right) = \\hat{\\imath}_m dp^+_{x_m} + \\left( 1-\\hat{\\imath}_m \\right) dp^-_{x_m}\n",
    "\\end{equation*}\n",
    "represents the conditional probability of price change equal to $x_m$ given $\\hat{\\imath}_m$, and $p(\\hat{\\imath}_m)$ is the density of the fitted skewnormal distribution evaluated at $\\hat{\\imath}_m$. \n",
    "\n",
    "Give the constraints that\n",
    "\\begin{align*}\n",
    "     &\\sum\\limits _{k=1}^N w_k = 1\\\\\n",
    "    &\\sum\\limits _{k=-N}^N dp^+_k = 1\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions of the computation of maximum likelihood\n",
    "def likelihood(dp_plus, p_I, w, N):\n",
    "    l = []\n",
    "    for i in range(2 * N + 1):\n",
    "        idx = np.where((w[:,1] >= (- N + i)) & (w[:,1] <  (- N + i + 1)))\n",
    "        X1 = w[idx][:,0]\n",
    "        X2 = 1 - w[idx][:,0]\n",
    "        l = np.append(l, (dp_plus[i] * X1 + dp_plus[2 * N - i] * X2) * np.array(p_I)[idx])\n",
    "    l = np.array(l)[~np.isnan(l)]\n",
    "    return - np.sum(np.log(l)) / len(l)\n",
    "\n",
    "def bayes(x):\n",
    "    dp_plus = x[N:]\n",
    "    weight = x[0:N] \n",
    "    #Compute avergae imbalance\n",
    "    imb = list(map(lambda x: imbalance_generate(x, weight, N, ask_sum, bid_sum), range(len(ask_sum))))\n",
    "    #Concatenate the imblance array with dp_a\n",
    "    w = np.append(np.array(imb).reshape(len(imb),1), np.array(dp_a).reshape(len(imb),1), axis = 1)\n",
    "    w = np.array(w[w[:,0] != None]).astype(float)\n",
    "    w = np.array(w[~np.isnan(w[:,0])])\n",
    "    #Fit the imbalance into skewnormal distribution abd compute the probability\n",
    "    a, loc, scale = skewnorm.fit(w[:,0])\n",
    "    p_I = skewnorm.pdf(w[:,0], a = a, scale = scale, loc = loc)\n",
    "    return likelihood(dp_plus, p_I, w, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the computation of maximum likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constraints\n",
    "equations = '+'.join('x' + str(i) for i in range(N)) + '==1' + '\\n' + '+'.join('x' + str(i) for i in range(N,2*N+5)) + '==1'\n",
    "cf = generate_constraint(generate_solvers(simplify(equations)))\n",
    "pf = generate_penalty(generate_conditions(equations), k=1e12)\n",
    "bnds = [(0,1)] * (N + 2 * N + 1)\n",
    "mon = VerboseMonitor(50)\n",
    "x0 = np.ones((2 * N + 1 + N))\n",
    "#Initial weights\n",
    "x0[:N] = x0[:N] / x0[:N].sum() \n",
    "#Initial dp_plus\n",
    "x0[N:] = x0[N:] / x0[N:].sum()\n",
    "#We can test this part serveral times to get a closer solution to global minimum, then optimize locally\n",
    "result1 = diffev2(bayes, x0 = x0, bounds = bnds, constraints=cf, penalty=pf, disp = True, full_output=True, itermon=mon, ftol = 1e-8)\n",
    "x0 = result1[0] #which is generated by above\n",
    "result = fmin_powell(bayes, x0 = x0, bounds = bnds, constraints=cf, penalty=pf, disp = True, itermon=mon, full_output=True, ftol = 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the weights and dp_plus\n",
    "fig = make_subplots(rows=1, cols=2, horizontal_spacing=0.04, shared_yaxes=True, subplot_titles= (r'$w$',r'$dp^+$') )\n",
    "fig.add_bar(x = np.arange(N), y = result[0][:N],row = 1, col = 1, showlegend = False)\n",
    "fig.add_bar(x = np.arange(-N,N+1), y = result[0][N:], marker_color='#4876FF',row = 1, col = 2, showlegend = False)\n",
    "fig.update_xaxes(dtick = 1)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Market Orders Price Impact $dq$\n",
    "$dq$ is the probability that the price moves by $k$ ticks triggered by market orders.\n",
    "Thus for each market order, compute\n",
    "\\begin{equation*}\n",
    "    F(H) = \\inf \\{ x\\in \\mathbb{N}_0 : \\sum_{k=0}^x v_k \\geq H\\}\n",
    "\\end{equation*}\n",
    "where $H$ is the volume of the market order. We derive $dq$ from the empirical distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the total market order volumes within the intervals\n",
    "def sum_H_generate(x, pointer1, pointer2, H):\n",
    "    left = pointer1[x]\n",
    "    right = pointer2[x]\n",
    "    if left >= right:\n",
    "        return\n",
    "    h = np.sum(H[left:right])\n",
    "    return h\n",
    "\n",
    "#Extract all the market orders\n",
    "m = lob.loc[(lob['reason'] == 'TRADE') & (lob['side'] == 'Buy') & (lob['market_state'] == 'Opening') | (lob['reason'] == 'TRADE') & (lob['side'] == 'Sell') & (lob['market_state'] == 'Open') ]\n",
    "time_ls = list(m['time'].values)\n",
    "pointer1 = np.array([takeClosest(time_ls, i) for i in s1])\n",
    "pointer2 = np.array([takeClosest(time_ls, i) for i in s])\n",
    "pointer3 = pointer1[np.where((pointer1 - pointer2)!=0)[0]]\n",
    "pointer4 = pointer2[np.where((pointer1 - pointer2)!=0)[0]]\n",
    "#Compute the empirical distribution of H \n",
    "H = np.array(list(map(lambda x: sum_H_generate(x, pointer3, pointer4, - m['book_change'].values), range(len(pointer3)))) )\n",
    "H = H[np.where(H != None)]\n",
    "#Set the upper bound of distribution of H as its 95% quantile and derive H range for simaulation\n",
    "H_em = np.zeros(int(np.quantile(H,0.95)/100))\n",
    "for i in range(len(H_em)):\n",
    "    H_em[i] = len(H[(i * 100 < H) & (H <= (i+1) * 100)]) / len(H)\n",
    "H = 100 * np.arange(int(np.quantile(H, 0.95) / 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since dq is in [-N,N] and by the definition of F(H), we have to consider limit order book 2 ticks deeper.\n",
    "N = N + 2\n",
    "#The inverse of cumulative sum of limit order book at H\n",
    "def inv(v, H):\n",
    "    s = 0\n",
    "    if H >= np.sum(v):\n",
    "        return N\n",
    "    for i in range(0,len(v)):\n",
    "        s = s + v[i]\n",
    "        if s > H:\n",
    "            return i\n",
    "        if s == H:\n",
    "            return i + 1\n",
    "        \n",
    "#Use monte carlo to simulate F(H) for each limit order book\n",
    "def q_simulation(df, H, H_em):\n",
    "    #HH = H[H <= np.sum(df)]\n",
    "    H_sample = choices(H, H_em, k = 100)\n",
    "    l = np.array(list(map(lambda x : inv(df,x), H_sample)))\n",
    "    return l \n",
    "name_ask = ['va' + str(i) for i in range(1, N + 1)]\n",
    "df = lob[name_ask].values\n",
    "data = np.array(list(map(lambda x: q_simulation(df[x], H, H_em), range(len(df)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute dq \n",
    "data = np.concatenate(data)\n",
    "data = data[data != None]\n",
    "qq = np.zeros(N)\n",
    "for i in range(0, N):\n",
    "    qq[i] = len(data[data >= i]) / len(data)\n",
    "dq = np.zeros(2 * N -1)\n",
    "dq[:N - 1] = qq[1 : N][::-1]\n",
    "dq[N:] = qq[1:N]\n",
    "dq[N - 1] = 2 * qq[0]\n",
    "dq= dq / np.sum(dq)\n",
    "dq = dq[1:len(dq)-1] \n",
    "dq"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
